---
title: AS12A：邏輯式性回歸 Logistic Regression
author: 中山大學管理學院 第八組
date: "`r Sys.time()`"
output: 
  html_document:
    highlight: pygments
    theme: flatly
    css: style.css
---

```{r results='hide', message=FALSE, warning=FALSE, echo=F}
# Formating Codes.  Do not change the codes in this chunk !!
rm(list=ls(all=T))
knitr::opts_chunk$set(comment = NA)
knitr::opts_knit$set(global.par = TRUE)
par(cex=0.8)
options(scipen=20, digits=5, width=80)
if(!require(pacman)) install.packages("pacman")
```
<hr>

```{r results='hide', message=FALSE, warning=FALSE}
pacman::p_load(ggplot2, dplyr)
```
<br><hr>

### 【A】簡單案例

+ 前情提要:邏輯式最男的不在於模型設定，而是如何解釋
  + 用途: 主要在於Y只能有兩個火特定數個選項時，運用X或多個X計算個變數中的變因，而出來的值為可能為這選項的"機率"

  + 選擇模型的基準為 "Accuracy 準確率" (水準設定於0.5時的準確率)
                     "AUC 辨識率"
                     (根據混淆矩陣中true positive rate & false positive rate 所形成的線圖，越靠近圖形左上角(任何水準都符合要求)越有力)，後者便是模型可行性下較為有力
  
  + 模型出現名詞:
     機率(p): 即類別出現機率
     勝率(odd): 出現機率和沒出現的比例( p/(1-p) )
     Logit: log(odd)
     Logistic Fucntion: 能將勝率經過公式轉換成機率(P=(1/1+EXP(-q)))
     
+ 資料：Binary Target Variable

```{r}
D = read.csv("data/quality.csv")  # Read in dataset
D = D[,c(14, 4, 5)]
names(D) = c("y", "x1", "x2")
table(D$y)
```

+ 方法：`glm(, family=binomial)` Generalize Liner Model

```{r}
glm1 = glm(y~x1+x2, D, family=binomial) #羅吉斯回歸function, binomial類別為二元
summary(glm1) #deviance為模型偏差
```

```{r}
b = coef(glm1); b   # extract the regression coef
```

+ $logit = f(x) = b_0 + b_1 x_1 + b_2 x_2$

+ $odd = Exp(logit)$

+ $Pr[y = 1] = prob = \frac{odd}{1+odd}$

Given `x1=3, x2=4`, what are the predicted logit, odd and probability?
```{r}
logit = sum(b * c(1, 3, 4)) #向量相乘，b0*1 b1*3(x1) b2*4(x2)
odd = exp(logit) #log的反函數
prob = odd/(1+odd) #勝率轉機率
c(logit=logit, odd=odd, prob=prob)
```

<span style="font-size:24px"> `r "\U1F5FF"` : </span>
What if `x1=2, x2=3`?

```{r}
logit = sum(b * c(1, 2, 3))
odd = exp(logit)
prob = odd/(1+odd)
c(logit=logit, odd=odd, prob=prob)
#  logit      odd     prob 
#-2.08505  0.12430  0.11056 
```
<br>

<span style="font-size:24px"> `r "\U1F4A1"` : </span>
`glm(family=binomial)`的功能：在 $\{x\}$ 的空間之中，找出區隔 $y$ 的(類別)界線

We can plot the line of `logit = 0` or `odd = 1, prob = 0.5` on the plane of $X$
```{r fig.width=3.6, fig.height=3.6}
par(cex=0.8, mar=c(4,4,1,1))
plot(D$x1, D$x2, col=2+D$y, pch=20, cex=1.2, xlab="X1", ylab="X2")
abline(-b[1]/b[3], -b[2]/b[3], col="blue", lty=3)
?abline
#藍色現為將紅點與綠點想辦法分出界線的線(因此一半綠一半紅，那條線機率=0.5)
#越靠近紅密集的地方機率越大，反之。
#abline(-b[1]/b[3], -b[2]/b[3]) 即logit(Y)=0帶入羅吉斯回歸中移項而得出，而logit=log(odd)=0 則odd=1 可推得p=0.5
```

Furthermore, we can translate probability, logit and coefficents to intercept & slope ...

$$f(x) = b_0 + b_1 x_1 + b_2 x_2 \; \Rightarrow \;  x_2 = \frac{f - b_0}{b_2} - \frac{b_1}{b_2}x_1$$

```{r  fig.width=3.6, fig.height=3.6}
p = seq(0.1,0.9,0.1)
logit = log(p/(1-p))
data.frame(prob = p, logit)
```

then mark the contours of proabilities into the scatter plot 
```{r  fig.width=3.6, fig.height=3.6}
par(cex=0.8, mar=c(4,4,1,1))
plot(D$x1, D$x2, col=2+D$y,
     pch=20, cex=1.3, xlab='X1', ylab='X2')
for(f in logit) {
  abline((f-b[1])/b[3], -b[2]/b[3], col=ifelse(f==0,'blue','cyan')) }

#abline(-b[1]/b[3], -b[2]/b[3]) 即logit(Y)=0帶入羅吉斯回歸中移項而得出，而logit=log(odd)=0 則odd=1 可推得p=0.5
#可知原式移項為 X2= y/b[3]-(b[1]/b[3])-(b[2]/b[3])
#因此帶入迴圈，可畫出Y比例漸進線(01~0.9 間隔為0.1)。
```

<span style="font-size:24px"> `r "\U1F5FF"` : </span>
What do the blue/cyan lines means?<br>

```{r}
#為將紅點與綠點想辦法分出界線的線,即Y是否為特定類別比例的漸進線。
#推論原因來自原本羅吉斯回歸{Y=b[1]+b[2]X1+b[3]X2}移項為 {X2= y/b[3]-(b[1]/b[3])-(b[2]/b[3])}，且Logit即為f(X)中的Y值(其中p=0.1~0.9 間隔為0.1)，而得出漸進線。

```

<span style="font-size:24px"> `r "\U1F5FF"` : </span>
Given any point in the figure above, how can you tell its (predicted) probability approximately?<br>

```{r}
#一種方法即為根據漸進線來推估大約Logit值
#另一種用剛剛的移項式子{X2= y/b[3]-(b[1]/b[3])-(b[2]/b[3])}來帶入要預測的X1,X2的值，可以有較佳的預測值
#再將Logit值帶入轉換式得機率P。

#抑或是進行混淆矩陣的方式並設定預估的機率水準來分析，並依據各自區域來做更多後續方法。
```

<br><hr>

### 【B】 邏輯式回歸

##### 機率、勝率(Odd)、Logit

+ Odd =  $p/(1-p)$

+ Logit = $log(odd)$ = $log(\frac{p}{1=p})$

+ $o = p/(1-p)$ ; $p = o/(1+o)$ ;  $logit = log(o)$

```{r fig.height=3.6, fig.width=7}
par(cex=0.8, mfcol=c(1,2))
curve(x/(1-x), 0.02, 0.98, col='cyan',lwd=2, 
    ylab='odd', xlab='p')
abline(v=seq(0,1,0.1), h=seq(0,50,5), col='lightgray', lty=3)
curve(log(x/(1-x)), 0.005, 0.995, lwd=2, col='purple', 
      ylab="logit",xlab='p')
abline(v=seq(0,1,0.1), h=seq(-5,5,1), col='lightgray', lty=3)
```
<br>

##### Logistic Function & Logistic Regression

+ Linear Model: $y = f(x) = b_0 + b_1x_1 + b_2x_2 + ...$

+ General Linear Model(GLM): $y = Link(f(x))$ 

+ Logistic Regression: $logit(y) = log(\frac{p}{1-p}) = f(x) \text{ where } p = prob[y=1]$ 

+ Logistic Function: $Logistic(F_x) = \frac{1}{1+Exp(-F_x)} = \frac{Exp(F_x)}{1+Exp(F_x)}$

```{r  fig.width=6, fig.height=3.6}
par(cex=0.8, mfrow=c(1,1))
curve(1/(1+exp(-x)), -5, 5, col='blue', lwd=2,main="Logistic Function",
      xlab="f(x): the logit of y = 1", ylab="the probability of y = 1")
abline(v=-5:5, h=seq(0,1,0.1), col='lightgray', lty=2)
abline(v=0,h=0.5,col='pink')
points(0,0.5,pch=20,cex=1.5,col='red')
```

<span style="font-size:24px"> `r "\U1F5FF"` : </span>
What are the definiion of `logit` & `logistic function`? What is the relationship between them?<br>

```{r}

#logit為羅輯斯回歸中計算Y(類別)出現的機率函數f(X)，以及出線機率和沒出現之間的比例( p/(1-p) )，Logit即為勝率odd的log值。
#logistic function即將Logit的值轉換成Y機率(Y)的轉換公式。
```


<br><br><br><hr>



